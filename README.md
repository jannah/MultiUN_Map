MultiUN_Map
===========

check requirements.txt for required modules
Run the below command inside your virtualenv to install all requieremnts
    
    pip install -r requirements.txt

To use the module, put this on top of your code

    MODULES_PATH = '''..\\modules\\multi_un_module.py'''
    import imp
    NF = imp.load_source('multi_un_module', MODULES_PATH)
    import multi_un_module as mun

#Key Files
## multi_un_module.ipynb (or .py) (modules/)
The file is a massive library of reusable components. It contains all the document loading and NLP functionality used by the app. The IPython Notebook contains all the code and documentation. The .py file a generated by converting the notebook using:
    
    ipython nbconvert --to python multi_un_module.ipynb

Here is a gist of the document: http://nbviewer.ipython.org/6726db02bf6bdfbc209a

## Examples.ipynb (modules/)
A demonstration of how to use the library
Gist: http://nbviewer.ipython.org/gist/jannah/793764fb47c230bb3b56

##Search the Corpus and Process.ipynb (modules/)
An IPython notebook was created to replicat the main functionality of the user interface.
Open the **"modules\Search the Corpus and Process.ipynb**" notebook

Sample Gist: 
http://nbviewer.ipython.org/gist/jannah/a110569ca7a6487d31ce

## Multi-process Scraping File (util/scrape/)
**Inspired by** [Sebastian Raschka](http://sebastianraschka.com)  
A module to scrape the UN website using the Selenium interactive scraper. The module can use mulitple processes to run parallel scrapes.

Gist: http://nbviewer.ipython.org/gist/jannah/e0dc1119aa9ba8a920a9

## Combine DocMap with Scrape (util/scrape/)
This module reads the docmap generated from the corpus with the information obtained from the scrape of the UN database into a single json map file.

Gist: http://nbviewer.ipython.org/gist/jannah/126896db28c620d48c47

## Extract Document Links (util/link_extraction/)
Extracts document links from the corpus using RegEx

Gist: http://nbviewer.ipython.org/gist/jannah/ada92933c5fe3fea4eee

## Document Interlinks Network Graph (util/link_extraction/)
Draws a network graph of document interlinks

Gist: http://nbviewer.ipython.org/gist/jannah/fc14826c35b798380007

# Test Data Files
for testing, extract the zip files
* data/TOP_100.zip --> data\multiUN.en\un\xml\en\TOP_100
* data/TOP_1000.zip --> data\multiUN.en\un\xml\en\TOP_1000

*Note*: Make sure the extracted files are in .gitignore

# Running the App
There are two ways to explore the functionality of the main module:

## UI Flask App
Simple Flask App to faclitate search and processing of documents.

###for to run on the full corpus
    python multiun.py 

###for to run on sample corpus (PICK ONE)
    python multiun.py map_100.json
    python multiun.py map_1000.json

##Search Notebook (Above)
