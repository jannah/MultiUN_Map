{
 "metadata": {
  "name": "",
  "signature": "sha256:782e2698d93d3b7b38be6d09d3391488fe37c7d4c58df0f0fbe9296999029250"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Extract Document links from text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This module extracts all the document references inside the text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MODULES_PATH = '''../../modules/multi_un_module.py'''\n",
      "import imp\n",
      "NF = imp.load_source('multi_un_module', MODULES_PATH)\n",
      "import multi_un_module as mun\n",
      "import nltk\n",
      "doc_path = 'C:/Users/Hassan/Documents/iSchool/NLP/United Nations/multiUN.en/un/xml/en'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "folder = ''\n",
      "# folder = 'TOP_100'\n",
      "docs = {}\n",
      "if len(folder)>0:\n",
      "    docs = mun.load_xml_files_by_year(year=folder)\n",
      "else:\n",
      "    docs = mun.load_xml_files(path=doc_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_links = mun.extract_links_from_documents(docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[doc_links[doc]['incoming'] for doc in doc_links if len(doc_links[doc]['incoming'])>0][:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculate statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_ids=dict([(docs[doc]['id'],doc) for doc in docs])\n",
      "total_outgoing_count = dict(nltk.FreqDist([d for doc in doc_links for d in doc_links[doc]['outgoing'] if d in doc_ids]).items())\n",
      "total_incoming_count = dict(nltk.FreqDist([d for doc in doc_links for d in doc_links[doc]['incoming'] if d in doc_ids]).items())\n",
      "total_outgoing_unique_count = dict(nltk.FreqDist([d for doc in doc_links for d in set(doc_links[doc]['outgoing']) if d in doc_ids]).items())\n",
      "total_incoming_unique_count = dict(nltk.FreqDist([d for doc in doc_links for d in set(doc_links[doc]['incoming']) if d in doc_ids]).items())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "link_list = sorted([(doc_ids[id], id, docs[doc_ids[id]]['year'],\n",
      "              total_outgoing_count[id] if id in total_outgoing_count else 0,\n",
      "              total_incoming_count[id] if id in total_incoming_count else 0, \n",
      "              total_outgoing_unique_count[id] if id in total_outgoing_unique_count else 0,\n",
      "              total_incoming_unique_count[id] if id in total_incoming_unique_count else 0) \n",
      "                    for id in doc_ids]\n",
      "                ,key=lambda (doc, id, year, toc, tic, touc, tiuc): touc+tiuc, reverse=True)\n",
      "link_list[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save link statistics to a file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('data/link_list_%s.csv'%folder, 'w') as f:\n",
      "    f.write('document, id, folder,total_out_count,total_in_count, total_out_unique_count, total_in_unique_count\\n')\n",
      "    f.write(\"\\n\".join(['\"%s\",\"%s\",\"%s\",%d,%d,%d,%d'%(v1,v2,v3,v4,v5,v6,v7) \n",
      "                       for (v1,v2,v3,v4,v5,v6,v7)  in link_list ]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save pairs for network charts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outgoing_pairs = [(id,k,v ) for id in doc_ids for (k,v) in nltk.FreqDist(doc_links[doc_ids[id]]['outgoing']).items()]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('data/link_pairs_%s.csv'%folder, 'w') as f:\n",
      "    f.write('source, target, value\\n')\n",
      "    f.write('\\n'.join(['\"%s\",\"%s\",%d'%(s,t,v) for (s,t,v) in outgoing_pairs]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}